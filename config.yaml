aws:
  region: "us-west-2"
  bedrock:
    # model_id: "anthropic.claude-3-haiku-20240307-v1:0"  # Claude 3 Haiku - 20 req/min rate limit
    model_id: "openai.gpt-oss-120b-1:0"
    # model_id: "anthropic.claude-sonnet-4-20250514-v1:0"
    # model_id: "anthropic.claude-opus-4-1-20250805-v1:0"
    # model_id: "anthropic.claude-opus-4-20250514-v1:0"
    # model_id: "openai.gpt-oss-20b-1:0"
    max_tokens: 4000
    temperature: 0.1

processing:
  input_folder: "inputs"
  output_folder: "outputs"
  
  # Filename formats - use placeholders: {folder_name}, {timestamp}, {date}
  individual_summary_filename: "{folder_name}_summary.md"
  global_summary_filename: "global_summary.md"
  
  # Input file patterns to look for (VTT files)
  input_file_patterns: ["*.vtt"]
  
summary:
  style: "comprehensive"  # Options: brief, comprehensive, detailed
  include_timestamps: true
  include_participants: true
  include_action_items: true

pdf:
  enabled: true                           # Enable/disable PDF generation
  filename: "complete_summary_report_{date}.pdf"  # PDF filename template
  title: "Meeting Summary Report"         # PDF document title
  include_table_of_contents: true         # Include TOC in PDF
  include_keyframes: true                 # Include keyframes in PDF
  page_size: "A4"                        # Page size (A4, Letter, etc.)
  font_size: 11                          # Base font size

keyframes:
  enabled: true              # Enable/disable keyframe extraction globally
  max_frames: 10              # Maximum keyframes per video (can be overridden by CLI)
  min_relevance_score: 0.3   # Minimum score threshold for keyframe candidates
  image_max_width: 1200      # Maximum width for optimized keyframe images (px)
  image_quality: 100          # Image quality for optimization (0-100)
  
  # Intelligent delay settings (in seconds)
  # These delays help capture the actual moment rather than just announcements
  # Adjust based on your typical meeting patterns
  delays:
    screen_sharing: 20.0        # "I will share my screen" -> wait for actual sharing
    screen_sharing_immediate: 1.0  # "I'm sharing my screen" -> already happening  
    demonstrations: 5.0        # "Let me show you" -> wait for demo to start
    technical: 3.0            # Technical discussions -> small delay for context
    transitions: 5.0          # "Moving on to" -> wait for transition to complete
    important: 1.0            # Important points -> small delay for emphasis
    questions: 1.0            # Q&A moments -> wait for response context

logging:
  level: "INFO"
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
